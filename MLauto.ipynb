{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b713d-b09f-409c-b824-2868def5e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== RANDOM FOREST with Recall-First Threshold (choose HIGHEST threshold meeting target) ====\n",
    "# - Uses explicit numeric/binary columns\n",
    "# - Cleans column names to safe identifiers\n",
    "# - 80:20 split with stratify\n",
    "# - Handles imbalance via class_weight=\"balanced\"\n",
    "# - Picks the HIGHEST threshold with recall >= TARGET_RECALL (reduces FP flood)\n",
    "# - Prints metrics at chosen threshold + 95% Wilson CIs + ROC-AUC/PR-AUC\n",
    "# - Plots top features\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import get_close_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# ========= 1) SETTINGS =========\n",
    "file_path  = #### Your CSV Path #####\n",
    "target_col = \"anyflag\"\n",
    "\n",
    "numeric_cols = [\n",
    "    'age','Q_Flag_BlastsAbn_Lympho','Q_Flag_Blasts','Q_Flag_AbnLympho',\n",
    "    'Q_Flag_LeftShift','Q_Flag_Atypical_Lympho','Q_Flag_RBC_Agglutination',\n",
    "    'Q_Flag_TurbidityHGBInterf','Q_Flag_Iron_Deficiency','Q_FlagHGB_Defect',\n",
    "    'Q_Flag_Fragments','Q_Flag_PLT_Clumps','swbc','srbc','shgb','shct',\n",
    "    'smcv','smch','smchc','splt','srdw','srdw_1','spdw','smpv','slcr','spct',\n",
    "    'snrbc','snrbcpercent','sn','sl','smo','seo','sbaso','snper','slper',\n",
    "    'smoper','seoper','sbaper','sig','sigper','splti','MicroR','MacroR',\n",
    "    'tnc','ba_n','ba_n_per','wbc_D','tnc_D','NEUT_1','NEUTpercent',\n",
    "    'LYMP','LYMPper','HFLC','HFLCper','BA_D','BA_D_1','NE_SSC','NE_SFL',\n",
    "    'NE_FSC','LY_X','LY_Y','LY_Z','MO_X','MO_Y','MO_Z','NE_WX','NE_WY',\n",
    "    'NE_WZ','LY_WX','LY_WY','LY_WZ','MO_WX','MO_WY','MO_WZ'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'sex','WARD','WBC_Abnormal','WBC_Suspect','RBC_Abnormal','RBC_Suspect',\n",
    "    'PLT_Abnormal','PLT_Suspect','IP_ABN_WBC_Abn_Scattergram',\n",
    "    'IP_ABN_WBC_Neutropenia','IP_ABN_WBC_Neutrophilia',\n",
    "    'IP_ABN_WBC_Lymphopenia','IP_ABN_WBC_Lymphocytosis',\n",
    "    'IP_ABN_WBC_Monocytosis','IP_ABN_WBC_Eosinophilia','IP_ABN_WBC_Basophilia',\n",
    "    'IP_ABN_WBC_Leukocytopenia','IP_ABN_WBC_Leukocytosis',\n",
    "    'IP_ABN_WBC_NRBC_Present','IP_ABN_WBC_IG_Present',\n",
    "    'IP_ABN_RBC_RBC_Abn_Distribution','IP_ABN_RBC_Dimorphic_Population',\n",
    "    'IP_ABN_RBC_Anisocytosis','IP_ABN_RBC_Microcytosis','IP_ABN_RBC_Macrocytosis',\n",
    "    'IP_ABN_RBC_Hypochromia','IP_ABN_RBC_Anemia','IP_ABN_RBC_Erythrocytosis',\n",
    "    'IP_ABN_RBC_RET_Abn_Scattergram','IP_ABN_RBC_Reticulocytosis',\n",
    "    'IP_ABN_PLT_PLT_Abn_Distribution','IP_ABN_PLT_Thrombocytopenia',\n",
    "    'IP_ABN_PLT_Thrombocytosis','IP_ABN_PLT_PLT_Abn_Scattergram',\n",
    "    'IP_SUS_WBC_Blasts_Abn_Lympho','IP_SUS_WBC_Blasts',\n",
    "    'IP_SUS_WBC_Abn_Lympho','IP_SUS_WBC_Left_Shift',\n",
    "    'IP_SUS_WBC_Atypical_Lympho','IP_SUS_RBC_RBC_Agglutination',\n",
    "    'IP_SUS_RBC_Turbidity_HGB_Interf','IP_SUS_RBC_Iron_Deficiency',\n",
    "    'IP_SUS_RBC_HGB_Defect','IP_SUS_RBC_Fragments','IP_SUS_PLT_PLT_Clumps'\n",
    "]\n",
    "\n",
    "test_size      = 0.20\n",
    "random_seed    = 42\n",
    "top_k_features = 20\n",
    "\n",
    "# IMPORTANT: set TARGET_RECALL to 0.95 and rerun; then set to 0.975 and rerun\n",
    "TARGET_RECALL  = 0.95\n",
    "\n",
    "# RF hyperparameters (adjust if needed)\n",
    "n_estimators      = 600\n",
    "max_depth         = None\n",
    "min_samples_leaf  = 5\n",
    "min_samples_split = 10\n",
    "max_features      = \"sqrt\"\n",
    "bootstrap         = True\n",
    "\n",
    "\n",
    "# ========= 2) HELPERS =========\n",
    "def clean_colname(col: str) -> str:\n",
    "    col = (col\n",
    "           .replace(\" NRBC Present\", \"_NRBC_Present\")\n",
    "           .replace(\" IG Present\", \"_IG_Present\")\n",
    "           .replace(\" Dimorphic Population\", \"_Dimorphic_Population\")\n",
    "           .replace(\" Atypical Lympho\", \"_Atypical_Lympho\")\n",
    "           .replace(\" Turbidity_HGB Interf\", \"_Turbidity_HGB_Interf\"))\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    col = re.sub(r'__+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "def to_binary(series: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"1\":1,\"0\":0,\"yes\":1,\"no\":0,\"true\":1,\"false\":0,\"y\":1,\"n\":0,\n",
    "        \"present\":1,\"absent\":0,\"pos\":1,\"neg\":0,\"positive\":1,\"negative\":0,\n",
    "        \"abnormal\":1,\"normal\":0,\"clumps\":1,\"no_clumps\":0\n",
    "    }\n",
    "    s = series.astype(str).str.lower().str.strip().map(mapping)\n",
    "    if s.isna().any():\n",
    "        num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        s = s.where(~num.notna(), (num.fillna(0) != 0).astype(int))\n",
    "    return s.fillna(0).astype(int)\n",
    "\n",
    "def wilson_ci(k: int, n: int, alpha: float = 0.05):\n",
    "    \"\"\"95% Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (float(\"nan\"), float(\"nan\"))\n",
    "    z = 1.959963984540054  # 95% CI\n",
    "    p = k / n\n",
    "    denom = 1 + (z**2)/n\n",
    "    center = (p + (z**2)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def approx_halfwidth(p: float, n: int):\n",
    "    \"\"\"Approx 95% CI half-width (planning).\"\"\"\n",
    "    if n <= 0:\n",
    "        return float(\"nan\")\n",
    "    z = 1.959963984540054\n",
    "    return z * math.sqrt(p*(1-p)/n)\n",
    "\n",
    "def metrics_with_cis(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    n_pos = tp + fn\n",
    "    n_neg = tn + fp\n",
    "\n",
    "    recall = tp / n_pos if n_pos else float(\"nan\")\n",
    "    spec   = tn / n_neg if n_neg else float(\"nan\")\n",
    "    ppv    = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv    = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"n_total\": int(len(y_true)), \"n_pos\": int(n_pos), \"n_neg\": int(n_neg),\n",
    "        \"recall\": recall, \"recall_ci\": wilson_ci(tp, n_pos),\n",
    "        \"specificity\": spec, \"specificity_ci\": wilson_ci(tn, n_neg),\n",
    "        \"ppv\": ppv, \"ppv_ci\": wilson_ci(tp, tp + fp) if (tp + fp) else (float(\"nan\"), float(\"nan\")),\n",
    "        \"npv\": npv, \"npv_ci\": wilson_ci(tn, tn + fn) if (tn + fn) else (float(\"nan\"), float(\"nan\")),\n",
    "    }\n",
    "\n",
    "def pct(x):  # helper for printing\n",
    "    return 100.0 * x\n",
    "\n",
    "\n",
    "# ========= 3) LOAD & CLEAN =========\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# ========= 4) VALIDATE REQUESTED COLUMNS =========\n",
    "want_cols = numeric_cols + binary_cols + [target_col]\n",
    "missing = [c for c in want_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Columns not found after cleaning. Adjust lists or cleaner:\")\n",
    "    for m in missing:\n",
    "        sug = get_close_matches(m, df.columns.tolist(), n=1, cutoff=0.7)\n",
    "        print(f\"  - {m}\" + (f\"  (closest: {sug[0]})\" if sug else \"\"))\n",
    "\n",
    "avail_numeric = [c for c in numeric_cols if c in df.columns]\n",
    "avail_binary  = [c for c in binary_cols  if c in df.columns]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# ========= 5) TYPE COERCION =========\n",
    "for c in avail_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in avail_binary:\n",
    "    df[c] = to_binary(df[c])\n",
    "\n",
    "df = df[~df[target_col].isna()].copy()\n",
    "\n",
    "y = df[target_col]\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = df[avail_numeric + avail_binary].fillna(0)\n",
    "\n",
    "# Drop constant columns\n",
    "const_cols = X.columns[X.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# ========= 6) SPLIT =========\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_seed, stratify=y\n",
    ")\n",
    "\n",
    "# ========= 7) RANDOM FOREST =========\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    min_samples_split=min_samples_split,\n",
    "    max_features=max_features,\n",
    "    bootstrap=bootstrap,\n",
    "    n_jobs=-1,\n",
    "    random_state=random_seed,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 8) THRESHOLD TUNING (HIGHEST threshold meeting recall target) =========\n",
    "if len(np.unique(y_train)) != 2:\n",
    "    raise ValueError(\"This script expects a binary target for threshold tuning.\")\n",
    "\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thr_candidates = np.unique(np.r_[0.0, np.round(y_proba, 6), 1.0])\n",
    "\n",
    "rows = []\n",
    "for thr in thr_candidates:\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_hat, zero_division=0)\n",
    "    fn   = int(((y_test == 1) & (y_hat == 0)).sum())\n",
    "    fp   = int(((y_test == 0) & (y_hat == 1)).sum())\n",
    "    rows.append((thr, prec, rec, fn, fp))\n",
    "\n",
    "thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"FN\",\"FP\"])\n",
    "\n",
    "meets = thr_df[thr_df[\"recall\"] >= TARGET_RECALL]\n",
    "if len(meets):\n",
    "    best_row = meets.sort_values(by=[\"threshold\"], ascending=[False]).iloc[0]\n",
    "else:\n",
    "    best_row = thr_df.sort_values(by=[\"recall\",\"threshold\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "BEST_THR = float(best_row[\"threshold\"])\n",
    "print(f\"\\nChosen threshold = {BEST_THR:.6f} | recall={best_row['recall']:.4f} \"\n",
    "      f\"| precision={best_row['precision']:.4f} | FN={best_row['FN']} | FP={best_row['FP']}\")\n",
    "\n",
    "y_pred_thr = (y_proba >= BEST_THR).astype(int)\n",
    "\n",
    "print(\"\\n=== Report @ chosen threshold (recall-first, highest threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "print(\"Confusion matrix @ chosen threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_thr))\n",
    "\n",
    "# ========= 9) METRICS + 95% Wilson CIs =========\n",
    "m = metrics_with_cis(y_test, y_pred_thr)\n",
    "\n",
    "print(\"\\n=== Metrics with 95% Wilson CIs ===\")\n",
    "print(f\"Test set: N={m['n_total']} | positives={m['n_pos']} | negatives={m['n_neg']}\")\n",
    "print(f\"Recall/Sensitivity = {m['recall']:.4f} (95% CI {m['recall_ci'][0]:.4f}–{m['recall_ci'][1]:.4f})\")\n",
    "print(f\"Specificity         = {m['specificity']:.4f} (95% CI {m['specificity_ci'][0]:.4f}–{m['specificity_ci'][1]:.4f})\")\n",
    "print(f\"PPV                 = {m['ppv']:.4f} (95% CI {m['ppv_ci'][0]:.4f}–{m['ppv_ci'][1]:.4f})\")\n",
    "print(f\"NPV                 = {m['npv']:.4f} (95% CI {m['npv_ci'][0]:.4f}–{m['npv_ci'][1]:.4f})\")\n",
    "\n",
    "# Adequacy: precision depends on #positives\n",
    "hw_if_95  = approx_halfwidth(0.95,  m[\"n_pos\"])\n",
    "hw_if_975 = approx_halfwidth(0.975, m[\"n_pos\"])\n",
    "print(\"\\n=== Recall precision (approx; depends on #positives in test set) ===\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.95  : ±{hw_if_95:.4f}\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.975 : ±{hw_if_975:.4f}\")\n",
    "\n",
    "# ========= 10) ROC-AUC + PR-AUC =========\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    order = np.argsort(rec_curve)\n",
    "    pr_auc = np.trapz(prec_curve[order], rec_curve[order])\n",
    "    print(f\"\\nROC-AUC={roc:.4f} | PR-AUC≈{pr_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Could not compute ROC/PR AUC: {e}\")\n",
    "\n",
    "# ========= 11) FEATURE IMPORTANCE PLOT =========\n",
    "importances = rf.feature_importances_\n",
    "imp = (pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "       .sort_values(\"Importance\", ascending=False)\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features:\")\n",
    "print(imp.head(top_k_features))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top = imp.head(top_k_features)[::-1]\n",
    "plt.barh(top[\"Feature\"], top[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_k_features} Feature Importances (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========= 12) DEPLOYMENT HINT =========\n",
    "# probs = rf.predict_proba(X_new)[:, 1]\n",
    "# preds = (probs >= BEST_THR).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7088c1-75a1-4248-932b-2418c46c9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== RANDOM FOREST with Recall-First Threshold (choose HIGHEST threshold meeting target) ====\n",
    "# - Uses explicit numeric/binary columns\n",
    "# - Cleans column names to safe identifiers\n",
    "# - 80:20 split with stratify\n",
    "# - Handles imbalance via class_weight=\"balanced\"\n",
    "# - Picks the HIGHEST threshold with recall >= TARGET_RECALL (reduces FP flood)\n",
    "# - Prints metrics at chosen threshold + 95% Wilson CIs + ROC-AUC/PR-AUC\n",
    "# - Plots top features\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import get_close_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# ========= 1) SETTINGS =========\n",
    "file_path  =  #### Your CSV Path #####\n",
    "target_col = \"anyflag\"\n",
    "\n",
    "numeric_cols = [\n",
    "    'age','Q_Flag_BlastsAbn_Lympho','Q_Flag_Blasts','Q_Flag_AbnLympho',\n",
    "    'Q_Flag_LeftShift','Q_Flag_Atypical_Lympho','Q_Flag_RBC_Agglutination',\n",
    "    'Q_Flag_TurbidityHGBInterf','Q_Flag_Iron_Deficiency','Q_FlagHGB_Defect',\n",
    "    'Q_Flag_Fragments','Q_Flag_PLT_Clumps','swbc','srbc','shgb','shct',\n",
    "    'smcv','smch','smchc','splt','srdw','srdw_1','spdw','smpv','slcr','spct',\n",
    "    'snrbc','snrbcpercent','sn','sl','smo','seo','sbaso','snper','slper',\n",
    "    'smoper','seoper','sbaper','sig','sigper','splti','MicroR','MacroR',\n",
    "    'tnc','ba_n','ba_n_per','wbc_D','tnc_D','NEUT_1','NEUTpercent',\n",
    "    'LYMP','LYMPper','HFLC','HFLCper','BA_D','BA_D_1','NE_SSC','NE_SFL',\n",
    "    'NE_FSC','LY_X','LY_Y','LY_Z','MO_X','MO_Y','MO_Z','NE_WX','NE_WY',\n",
    "    'NE_WZ','LY_WX','LY_WY','LY_WZ','MO_WX','MO_WY','MO_WZ'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'sex','WARD','WBC_Abnormal','WBC_Suspect','RBC_Abnormal','RBC_Suspect',\n",
    "    'PLT_Abnormal','PLT_Suspect','IP_ABN_WBC_Abn_Scattergram',\n",
    "    'IP_ABN_WBC_Neutropenia','IP_ABN_WBC_Neutrophilia',\n",
    "    'IP_ABN_WBC_Lymphopenia','IP_ABN_WBC_Lymphocytosis',\n",
    "    'IP_ABN_WBC_Monocytosis','IP_ABN_WBC_Eosinophilia','IP_ABN_WBC_Basophilia',\n",
    "    'IP_ABN_WBC_Leukocytopenia','IP_ABN_WBC_Leukocytosis',\n",
    "    'IP_ABN_WBC_NRBC_Present','IP_ABN_WBC_IG_Present',\n",
    "    'IP_ABN_RBC_RBC_Abn_Distribution','IP_ABN_RBC_Dimorphic_Population',\n",
    "    'IP_ABN_RBC_Anisocytosis','IP_ABN_RBC_Microcytosis','IP_ABN_RBC_Macrocytosis',\n",
    "    'IP_ABN_RBC_Hypochromia','IP_ABN_RBC_Anemia','IP_ABN_RBC_Erythrocytosis',\n",
    "    'IP_ABN_RBC_RET_Abn_Scattergram','IP_ABN_RBC_Reticulocytosis',\n",
    "    'IP_ABN_PLT_PLT_Abn_Distribution','IP_ABN_PLT_Thrombocytopenia',\n",
    "    'IP_ABN_PLT_Thrombocytosis','IP_ABN_PLT_PLT_Abn_Scattergram',\n",
    "    'IP_SUS_WBC_Blasts_Abn_Lympho','IP_SUS_WBC_Blasts',\n",
    "    'IP_SUS_WBC_Abn_Lympho','IP_SUS_WBC_Left_Shift',\n",
    "    'IP_SUS_WBC_Atypical_Lympho','IP_SUS_RBC_RBC_Agglutination',\n",
    "    'IP_SUS_RBC_Turbidity_HGB_Interf','IP_SUS_RBC_Iron_Deficiency',\n",
    "    'IP_SUS_RBC_HGB_Defect','IP_SUS_RBC_Fragments','IP_SUS_PLT_PLT_Clumps'\n",
    "]\n",
    "\n",
    "test_size      = 0.20\n",
    "random_seed    = 42\n",
    "top_k_features = 20\n",
    "\n",
    "# IMPORTANT: set TARGET_RECALL to 0.95 and rerun; then set to 0.975 and rerun\n",
    "TARGET_RECALL  = 0.975\n",
    "\n",
    "# RF hyperparameters (adjust if needed)\n",
    "n_estimators      = 600\n",
    "max_depth         = None\n",
    "min_samples_leaf  = 5\n",
    "min_samples_split = 10\n",
    "max_features      = \"sqrt\"\n",
    "bootstrap         = True\n",
    "\n",
    "\n",
    "# ========= 2) HELPERS =========\n",
    "def clean_colname(col: str) -> str:\n",
    "    col = (col\n",
    "           .replace(\" NRBC Present\", \"_NRBC_Present\")\n",
    "           .replace(\" IG Present\", \"_IG_Present\")\n",
    "           .replace(\" Dimorphic Population\", \"_Dimorphic_Population\")\n",
    "           .replace(\" Atypical Lympho\", \"_Atypical_Lympho\")\n",
    "           .replace(\" Turbidity_HGB Interf\", \"_Turbidity_HGB_Interf\"))\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    col = re.sub(r'__+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "def to_binary(series: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"1\":1,\"0\":0,\"yes\":1,\"no\":0,\"true\":1,\"false\":0,\"y\":1,\"n\":0,\n",
    "        \"present\":1,\"absent\":0,\"pos\":1,\"neg\":0,\"positive\":1,\"negative\":0,\n",
    "        \"abnormal\":1,\"normal\":0,\"clumps\":1,\"no_clumps\":0\n",
    "    }\n",
    "    s = series.astype(str).str.lower().str.strip().map(mapping)\n",
    "    if s.isna().any():\n",
    "        num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        s = s.where(~num.notna(), (num.fillna(0) != 0).astype(int))\n",
    "    return s.fillna(0).astype(int)\n",
    "\n",
    "def wilson_ci(k: int, n: int, alpha: float = 0.05):\n",
    "    \"\"\"95% Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (float(\"nan\"), float(\"nan\"))\n",
    "    z = 1.959963984540054  # 95% CI\n",
    "    p = k / n\n",
    "    denom = 1 + (z**2)/n\n",
    "    center = (p + (z**2)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def approx_halfwidth(p: float, n: int):\n",
    "    \"\"\"Approx 95% CI half-width (planning).\"\"\"\n",
    "    if n <= 0:\n",
    "        return float(\"nan\")\n",
    "    z = 1.959963984540054\n",
    "    return z * math.sqrt(p*(1-p)/n)\n",
    "\n",
    "def metrics_with_cis(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    n_pos = tp + fn\n",
    "    n_neg = tn + fp\n",
    "\n",
    "    recall = tp / n_pos if n_pos else float(\"nan\")\n",
    "    spec   = tn / n_neg if n_neg else float(\"nan\")\n",
    "    ppv    = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv    = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"n_total\": int(len(y_true)), \"n_pos\": int(n_pos), \"n_neg\": int(n_neg),\n",
    "        \"recall\": recall, \"recall_ci\": wilson_ci(tp, n_pos),\n",
    "        \"specificity\": spec, \"specificity_ci\": wilson_ci(tn, n_neg),\n",
    "        \"ppv\": ppv, \"ppv_ci\": wilson_ci(tp, tp + fp) if (tp + fp) else (float(\"nan\"), float(\"nan\")),\n",
    "        \"npv\": npv, \"npv_ci\": wilson_ci(tn, tn + fn) if (tn + fn) else (float(\"nan\"), float(\"nan\")),\n",
    "    }\n",
    "\n",
    "def pct(x):  # helper for printing\n",
    "    return 100.0 * x\n",
    "\n",
    "\n",
    "# ========= 3) LOAD & CLEAN =========\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# ========= 4) VALIDATE REQUESTED COLUMNS =========\n",
    "want_cols = numeric_cols + binary_cols + [target_col]\n",
    "missing = [c for c in want_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Columns not found after cleaning. Adjust lists or cleaner:\")\n",
    "    for m in missing:\n",
    "        sug = get_close_matches(m, df.columns.tolist(), n=1, cutoff=0.7)\n",
    "        print(f\"  - {m}\" + (f\"  (closest: {sug[0]})\" if sug else \"\"))\n",
    "\n",
    "avail_numeric = [c for c in numeric_cols if c in df.columns]\n",
    "avail_binary  = [c for c in binary_cols  if c in df.columns]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# ========= 5) TYPE COERCION =========\n",
    "for c in avail_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in avail_binary:\n",
    "    df[c] = to_binary(df[c])\n",
    "\n",
    "df = df[~df[target_col].isna()].copy()\n",
    "\n",
    "y = df[target_col]\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = df[avail_numeric + avail_binary].fillna(0)\n",
    "\n",
    "# Drop constant columns\n",
    "const_cols = X.columns[X.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# ========= 6) SPLIT =========\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_seed, stratify=y\n",
    ")\n",
    "\n",
    "# ========= 7) RANDOM FOREST =========\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    min_samples_split=min_samples_split,\n",
    "    max_features=max_features,\n",
    "    bootstrap=bootstrap,\n",
    "    n_jobs=-1,\n",
    "    random_state=random_seed,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# ========= 8) THRESHOLD TUNING (HIGHEST threshold meeting recall target) =========\n",
    "if len(np.unique(y_train)) != 2:\n",
    "    raise ValueError(\"This script expects a binary target for threshold tuning.\")\n",
    "\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thr_candidates = np.unique(np.r_[0.0, np.round(y_proba, 6), 1.0])\n",
    "\n",
    "rows = []\n",
    "for thr in thr_candidates:\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_hat, zero_division=0)\n",
    "    fn   = int(((y_test == 1) & (y_hat == 0)).sum())\n",
    "    fp   = int(((y_test == 0) & (y_hat == 1)).sum())\n",
    "    rows.append((thr, prec, rec, fn, fp))\n",
    "\n",
    "thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"FN\",\"FP\"])\n",
    "\n",
    "meets = thr_df[thr_df[\"recall\"] >= TARGET_RECALL]\n",
    "if len(meets):\n",
    "    best_row = meets.sort_values(by=[\"threshold\"], ascending=[False]).iloc[0]\n",
    "else:\n",
    "    best_row = thr_df.sort_values(by=[\"recall\",\"threshold\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "BEST_THR = float(best_row[\"threshold\"])\n",
    "print(f\"\\nChosen threshold = {BEST_THR:.6f} | recall={best_row['recall']:.4f} \"\n",
    "      f\"| precision={best_row['precision']:.4f} | FN={best_row['FN']} | FP={best_row['FP']}\")\n",
    "\n",
    "y_pred_thr = (y_proba >= BEST_THR).astype(int)\n",
    "\n",
    "print(\"\\n=== Report @ chosen threshold (recall-first, highest threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "print(\"Confusion matrix @ chosen threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_thr))\n",
    "\n",
    "# ========= 9) METRICS + 95% Wilson CIs =========\n",
    "m = metrics_with_cis(y_test, y_pred_thr)\n",
    "\n",
    "print(\"\\n=== Metrics with 95% Wilson CIs ===\")\n",
    "print(f\"Test set: N={m['n_total']} | positives={m['n_pos']} | negatives={m['n_neg']}\")\n",
    "print(f\"Recall/Sensitivity = {m['recall']:.4f} (95% CI {m['recall_ci'][0]:.4f}–{m['recall_ci'][1]:.4f})\")\n",
    "print(f\"Specificity         = {m['specificity']:.4f} (95% CI {m['specificity_ci'][0]:.4f}–{m['specificity_ci'][1]:.4f})\")\n",
    "print(f\"PPV                 = {m['ppv']:.4f} (95% CI {m['ppv_ci'][0]:.4f}–{m['ppv_ci'][1]:.4f})\")\n",
    "print(f\"NPV                 = {m['npv']:.4f} (95% CI {m['npv_ci'][0]:.4f}–{m['npv_ci'][1]:.4f})\")\n",
    "\n",
    "# Adequacy: precision depends on #positives\n",
    "hw_if_95  = approx_halfwidth(0.95,  m[\"n_pos\"])\n",
    "hw_if_975 = approx_halfwidth(0.975, m[\"n_pos\"])\n",
    "print(\"\\n=== Recall precision (approx; depends on #positives in test set) ===\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.95  : ±{hw_if_95:.4f}\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.975 : ±{hw_if_975:.4f}\")\n",
    "\n",
    "# ========= 10) ROC-AUC + PR-AUC =========\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    order = np.argsort(rec_curve)\n",
    "    pr_auc = np.trapz(prec_curve[order], rec_curve[order])\n",
    "    print(f\"\\nROC-AUC={roc:.4f} | PR-AUC≈{pr_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Could not compute ROC/PR AUC: {e}\")\n",
    "\n",
    "# ========= 11) FEATURE IMPORTANCE PLOT =========\n",
    "importances = rf.feature_importances_\n",
    "imp = (pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "       .sort_values(\"Importance\", ascending=False)\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features:\")\n",
    "print(imp.head(top_k_features))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top = imp.head(top_k_features)[::-1]\n",
    "plt.barh(top[\"Feature\"], top[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_k_features} Feature Importances (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========= 12) DEPLOYMENT HINT =========\n",
    "# probs = rf.predict_proba(X_new)[:, 1]\n",
    "# preds = (probs >= BEST_THR).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ffcc0-064e-48dc-8ce1-40ec4df58dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DECISION TREE with Recall-First Threshold (choose HIGHEST threshold meeting target) ====\n",
    "# - Uses explicit numeric/binary columns\n",
    "# - Cleans column names to safe identifiers\n",
    "# - 80:20 split with stratify\n",
    "# - Handles imbalance via class_weight=\"balanced\"\n",
    "# - Picks the HIGHEST threshold with recall >= TARGET_RECALL (reduces FP flood)\n",
    "# - Prints metrics at chosen threshold + 95% Wilson CIs\n",
    "# - Plots top features and top tree levels\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import get_close_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "\n",
    "# ========= 1) SETTINGS =========\n",
    "file_path  =  #### Your CSV Path #####\n",
    "target_col = \"anyflag\"\n",
    "\n",
    "numeric_cols = [\n",
    "    'age','Q_Flag_BlastsAbn_Lympho','Q_Flag_Blasts','Q_Flag_AbnLympho',\n",
    "    'Q_Flag_LeftShift','Q_Flag_Atypical_Lympho','Q_Flag_RBC_Agglutination',\n",
    "    'Q_Flag_TurbidityHGBInterf','Q_Flag_Iron_Deficiency','Q_FlagHGB_Defect',\n",
    "    'Q_Flag_Fragments','Q_Flag_PLT_Clumps','swbc','srbc','shgb','shct',\n",
    "    'smcv','smch','smchc','splt','srdw','srdw_1','spdw','smpv','slcr','spct',\n",
    "    'snrbc','snrbcpercent','sn','sl','smo','seo','sbaso','snper','slper',\n",
    "    'smoper','seoper','sbaper','sig','sigper','splti','MicroR','MacroR',\n",
    "    'tnc','ba_n','ba_n_per','wbc_D','tnc_D','NEUT_1','NEUTpercent',\n",
    "    'LYMP','LYMPper','HFLC','HFLCper','BA_D','BA_D_1','NE_SSC','NE_SFL',\n",
    "    'NE_FSC','LY_X','LY_Y','LY_Z','MO_X','MO_Y','MO_Z','NE_WX','NE_WY',\n",
    "    'NE_WZ','LY_WX','LY_WY','LY_WZ','MO_WX','MO_WY','MO_WZ'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'sex','WARD','WBC_Abnormal','WBC_Suspect','RBC_Abnormal','RBC_Suspect',\n",
    "    'PLT_Abnormal','PLT_Suspect','IP_ABN_WBC_Abn_Scattergram',\n",
    "    'IP_ABN_WBC_Neutropenia','IP_ABN_WBC_Neutrophilia',\n",
    "    'IP_ABN_WBC_Lymphopenia','IP_ABN_WBC_Lymphocytosis',\n",
    "    'IP_ABN_WBC_Monocytosis','IP_ABN_WBC_Eosinophilia','IP_ABN_WBC_Basophilia',\n",
    "    'IP_ABN_WBC_Leukocytopenia','IP_ABN_WBC_Leukocytosis',\n",
    "    'IP_ABN_WBC_NRBC_Present','IP_ABN_WBC_IG_Present',\n",
    "    'IP_ABN_RBC_RBC_Abn_Distribution','IP_ABN_RBC_Dimorphic_Population',\n",
    "    'IP_ABN_RBC_Anisocytosis','IP_ABN_RBC_Microcytosis','IP_ABN_RBC_Macrocytosis',\n",
    "    'IP_ABN_RBC_Hypochromia','IP_ABN_RBC_Anemia','IP_ABN_RBC_Erythrocytosis',\n",
    "    'IP_ABN_RBC_RET_Abn_Scattergram','IP_ABN_RBC_Reticulocytosis',\n",
    "    'IP_ABN_PLT_PLT_Abn_Distribution','IP_ABN_PLT_Thrombocytopenia',\n",
    "    'IP_ABN_PLT_Thrombocytosis','IP_ABN_PLT_PLT_Abn_Scattergram',\n",
    "    'IP_SUS_WBC_Blasts_Abn_Lympho','IP_SUS_WBC_Blasts',\n",
    "    'IP_SUS_WBC_Abn_Lympho','IP_SUS_WBC_Left_Shift',\n",
    "    'IP_SUS_WBC_Atypical_Lympho','IP_SUS_RBC_RBC_Agglutination',\n",
    "    'IP_SUS_RBC_Turbidity_HGB_Interf','IP_SUS_RBC_Iron_Deficiency',\n",
    "    'IP_SUS_RBC_HGB_Defect','IP_SUS_RBC_Fragments','IP_SUS_PLT_PLT_Clumps'\n",
    "]\n",
    "\n",
    "test_size      = 0.20\n",
    "random_seed    = 42\n",
    "top_k_features = 20\n",
    "TARGET_RECALL  = 0.95   # rerun with 0.975 for the 97.5% operating point\n",
    "\n",
    "# Tree complexity controls (tune as needed)\n",
    "criterion         = \"gini\"   # or \"entropy\" / \"log_loss\"\n",
    "max_depth         = 10\n",
    "min_samples_split = 20\n",
    "min_samples_leaf  = 10\n",
    "ccp_alpha         = 0.0\n",
    "\n",
    "# ========= 2) HELPERS =========\n",
    "def clean_colname(col: str) -> str:\n",
    "    col = (col\n",
    "           .replace(\" NRBC Present\", \"_NRBC_Present\")\n",
    "           .replace(\" IG Present\", \"_IG_Present\")\n",
    "           .replace(\" Dimorphic Population\", \"_Dimorphic_Population\")\n",
    "           .replace(\" Atypical Lympho\", \"_Atypical_Lympho\")\n",
    "           .replace(\" Turbidity_HGB Interf\", \"_Turbidity_HGB_Interf\"))\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    col = re.sub(r'__+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "def to_binary(series: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"1\":1,\"0\":0,\"yes\":1,\"no\":0,\"true\":1,\"false\":0,\"y\":1,\"n\":0,\n",
    "        \"present\":1,\"absent\":0,\"pos\":1,\"neg\":0,\"positive\":1,\"negative\":0,\n",
    "        \"abnormal\":1,\"normal\":0,\"clumps\":1,\"no_clumps\":0\n",
    "    }\n",
    "    s = series.astype(str).str.lower().str.strip().map(mapping)\n",
    "    if s.isna().any():\n",
    "        num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        s = s.where(~num.notna(), (num.fillna(0) != 0).astype(int))\n",
    "    return s.fillna(0).astype(int)\n",
    "\n",
    "def wilson_ci(k: int, n: int, alpha: float = 0.05):\n",
    "    \"\"\"95% Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (float(\"nan\"), float(\"nan\"))\n",
    "    z = 1.959963984540054\n",
    "    p = k / n\n",
    "    denom = 1 + (z**2)/n\n",
    "    center = (p + (z**2)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def metrics_with_cis(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    n_pos = tp + fn\n",
    "    n_neg = tn + fp\n",
    "\n",
    "    recall = tp / n_pos if n_pos else float(\"nan\")\n",
    "    spec   = tn / n_neg if n_neg else float(\"nan\")\n",
    "    ppv    = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv    = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"n_total\": int(len(y_true)), \"n_pos\": int(n_pos), \"n_neg\": int(n_neg),\n",
    "        \"recall\": recall, \"recall_ci\": wilson_ci(tp, n_pos),\n",
    "        \"specificity\": spec, \"specificity_ci\": wilson_ci(tn, n_neg),\n",
    "        \"ppv\": ppv, \"ppv_ci\": wilson_ci(tp, tp + fp) if (tp + fp) else (float(\"nan\"), float(\"nan\")),\n",
    "        \"npv\": npv, \"npv_ci\": wilson_ci(tn, tn + fn) if (tn + fn) else (float(\"nan\"), float(\"nan\")),\n",
    "    }\n",
    "\n",
    "def pct(x):\n",
    "    return 100.0 * x\n",
    "\n",
    "# ========= 3) LOAD & CLEAN COLUMN NAMES =========\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# ========= 4) VALIDATE REQUESTED COLUMNS =========\n",
    "want_cols = numeric_cols + binary_cols + [target_col]\n",
    "missing = [c for c in want_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Columns not found after cleaning. Adjust lists or cleaner:\")\n",
    "    for m in missing:\n",
    "        sug = get_close_matches(m, df.columns.tolist(), n=1, cutoff=0.7)\n",
    "        print(f\"  - {m}\" + (f\"  (closest: {sug[0]})\" if sug else \"\"))\n",
    "\n",
    "avail_numeric = [c for c in numeric_cols if c in df.columns]\n",
    "avail_binary  = [c for c in binary_cols  if c in df.columns]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# ========= 5) TYPE COERCION =========\n",
    "for c in avail_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in avail_binary:\n",
    "    df[c] = to_binary(df[c])\n",
    "\n",
    "df = df[~df[target_col].isna()].copy()\n",
    "\n",
    "y = df[target_col]\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = df[avail_numeric + avail_binary].fillna(0)\n",
    "\n",
    "const_cols = X.columns[X.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# ========= 6) SPLIT =========\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_seed, stratify=y\n",
    ")\n",
    "\n",
    "# ========= 7) DECISION TREE =========\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion=criterion,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=random_seed,\n",
    "    ccp_alpha=ccp_alpha\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# ========= 8) THRESHOLD TUNING (HIGHEST threshold meeting recall target) =========\n",
    "if len(np.unique(y_train)) != 2:\n",
    "    raise ValueError(\"This script expects a binary target for threshold tuning.\")\n",
    "\n",
    "y_proba = dt.predict_proba(X_test)[:, 1]\n",
    "thr_candidates = np.unique(np.r_[0.0, np.round(y_proba, 6), 1.0])\n",
    "\n",
    "rows = []\n",
    "for thr in thr_candidates:\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_hat, zero_division=0)\n",
    "    fn   = int(((y_test == 1) & (y_hat == 0)).sum())\n",
    "    fp   = int(((y_test == 0) & (y_hat == 1)).sum())\n",
    "    rows.append((thr, prec, rec, fn, fp))\n",
    "\n",
    "thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"FN\",\"FP\"])\n",
    "\n",
    "meets = thr_df[thr_df[\"recall\"] >= TARGET_RECALL]\n",
    "if len(meets):\n",
    "    best_row = meets.sort_values(by=[\"threshold\"], ascending=[False]).iloc[0]\n",
    "else:\n",
    "    best_row = thr_df.sort_values(by=[\"recall\",\"threshold\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "BEST_THR = float(best_row[\"threshold\"])\n",
    "print(f\"\\nChosen threshold = {BEST_THR:.6f} | recall={best_row['recall']:.4f} \"\n",
    "      f\"| precision={best_row['precision']:.4f} | FN={best_row['FN']} | FP={best_row['FP']}\")\n",
    "\n",
    "y_pred_thr = (y_proba >= BEST_THR).astype(int)\n",
    "\n",
    "print(\"\\n=== Report @ chosen threshold (recall-first, highest threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "print(\"Confusion matrix @ chosen threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_thr))\n",
    "\n",
    "# ========= 9) METRICS + 95% Wilson CIs =========\n",
    "m = metrics_with_cis(y_test, y_pred_thr)\n",
    "\n",
    "print(\"\\n=== Metrics with 95% Wilson CIs ===\")\n",
    "print(f\"Test set: N={m['n_total']} | positives={m['n_pos']} | negatives={m['n_neg']}\")\n",
    "print(f\"Recall/Sensitivity = {m['recall']:.4f} (95% CI {m['recall_ci'][0]:.4f}–{m['recall_ci'][1]:.4f})\")\n",
    "print(f\"Specificity         = {m['specificity']:.4f} (95% CI {m['specificity_ci'][0]:.4f}–{m['specificity_ci'][1]:.4f})\")\n",
    "print(f\"PPV                 = {m['ppv']:.4f} (95% CI {m['ppv_ci'][0]:.4f}–{m['ppv_ci'][1]:.4f})\")\n",
    "print(f\"NPV                 = {m['npv']:.4f} (95% CI {m['npv_ci'][0]:.4f}–{m['npv_ci'][1]:.4f})\")\n",
    "\n",
    "# ========= 10) ROC-AUC + PR-AUC =========\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    order = np.argsort(rec_curve)\n",
    "    pr_auc = np.trapz(prec_curve[order], rec_curve[order])\n",
    "    print(f\"\\nROC-AUC={roc:.4f} | PR-AUC≈{pr_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Could not compute ROC/PR AUC: {e}\")\n",
    "\n",
    "# ========= 11) TOP FEATURES =========\n",
    "importances = dt.feature_importances_\n",
    "imp = (pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "       .sort_values(\"Importance\", ascending=False)\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features:\")\n",
    "print(imp.head(top_k_features))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top = imp.head(top_k_features)[::-1]\n",
    "plt.barh(top[\"Feature\"], top[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_k_features} Feature Importances (Decision Tree)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========= 12) TREE SUMMARY (TOP LEVELS) =========\n",
    "print(\"\\n=== Tree (text summary, top levels) ===\")\n",
    "print(export_text(dt, feature_names=list(X.columns), max_depth=3))\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plot_tree(\n",
    "    dt,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"0\", \"1\"],\n",
    "    filled=True, rounded=True, max_depth=3, fontsize=8\n",
    ")\n",
    "plt.title(\"Decision Tree (top levels)\")\n",
    "plt.show()\n",
    "\n",
    "# ========= 13) DEPLOYMENT HINT =========\n",
    "# probs = dt.predict_proba(X_new)[:, 1]\n",
    "# preds = (probs >= BEST_THR).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55bab1d-5db1-4b81-aa1d-91f913bb8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DECISION TREE with Recall-First Threshold (choose HIGHEST threshold meeting target) ====\n",
    "# - Uses explicit numeric/binary columns\n",
    "# - Cleans column names to safe identifiers\n",
    "# - 80:20 split with stratify\n",
    "# - Handles imbalance via class_weight=\"balanced\"\n",
    "# - Picks the HIGHEST threshold with recall >= TARGET_RECALL (reduces FP flood)\n",
    "# - Prints metrics at chosen threshold + 95% Wilson CIs\n",
    "# - Plots top features and top tree levels\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import get_close_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "\n",
    "# ========= 1) SETTINGS =========\n",
    "file_path  =  #### Your CSV Path #####\n",
    "target_col = \"anyflag\"\n",
    "\n",
    "numeric_cols = [\n",
    "    'age','Q_Flag_BlastsAbn_Lympho','Q_Flag_Blasts','Q_Flag_AbnLympho',\n",
    "    'Q_Flag_LeftShift','Q_Flag_Atypical_Lympho','Q_Flag_RBC_Agglutination',\n",
    "    'Q_Flag_TurbidityHGBInterf','Q_Flag_Iron_Deficiency','Q_FlagHGB_Defect',\n",
    "    'Q_Flag_Fragments','Q_Flag_PLT_Clumps','swbc','srbc','shgb','shct',\n",
    "    'smcv','smch','smchc','splt','srdw','srdw_1','spdw','smpv','slcr','spct',\n",
    "    'snrbc','snrbcpercent','sn','sl','smo','seo','sbaso','snper','slper',\n",
    "    'smoper','seoper','sbaper','sig','sigper','splti','MicroR','MacroR',\n",
    "    'tnc','ba_n','ba_n_per','wbc_D','tnc_D','NEUT_1','NEUTpercent',\n",
    "    'LYMP','LYMPper','HFLC','HFLCper','BA_D','BA_D_1','NE_SSC','NE_SFL',\n",
    "    'NE_FSC','LY_X','LY_Y','LY_Z','MO_X','MO_Y','MO_Z','NE_WX','NE_WY',\n",
    "    'NE_WZ','LY_WX','LY_WY','LY_WZ','MO_WX','MO_WY','MO_WZ'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'sex','WARD','WBC_Abnormal','WBC_Suspect','RBC_Abnormal','RBC_Suspect',\n",
    "    'PLT_Abnormal','PLT_Suspect','IP_ABN_WBC_Abn_Scattergram',\n",
    "    'IP_ABN_WBC_Neutropenia','IP_ABN_WBC_Neutrophilia',\n",
    "    'IP_ABN_WBC_Lymphopenia','IP_ABN_WBC_Lymphocytosis',\n",
    "    'IP_ABN_WBC_Monocytosis','IP_ABN_WBC_Eosinophilia','IP_ABN_WBC_Basophilia',\n",
    "    'IP_ABN_WBC_Leukocytopenia','IP_ABN_WBC_Leukocytosis',\n",
    "    'IP_ABN_WBC_NRBC_Present','IP_ABN_WBC_IG_Present',\n",
    "    'IP_ABN_RBC_RBC_Abn_Distribution','IP_ABN_RBC_Dimorphic_Population',\n",
    "    'IP_ABN_RBC_Anisocytosis','IP_ABN_RBC_Microcytosis','IP_ABN_RBC_Macrocytosis',\n",
    "    'IP_ABN_RBC_Hypochromia','IP_ABN_RBC_Anemia','IP_ABN_RBC_Erythrocytosis',\n",
    "    'IP_ABN_RBC_RET_Abn_Scattergram','IP_ABN_RBC_Reticulocytosis',\n",
    "    'IP_ABN_PLT_PLT_Abn_Distribution','IP_ABN_PLT_Thrombocytopenia',\n",
    "    'IP_ABN_PLT_Thrombocytosis','IP_ABN_PLT_PLT_Abn_Scattergram',\n",
    "    'IP_SUS_WBC_Blasts_Abn_Lympho','IP_SUS_WBC_Blasts',\n",
    "    'IP_SUS_WBC_Abn_Lympho','IP_SUS_WBC_Left_Shift',\n",
    "    'IP_SUS_WBC_Atypical_Lympho','IP_SUS_RBC_RBC_Agglutination',\n",
    "    'IP_SUS_RBC_Turbidity_HGB_Interf','IP_SUS_RBC_Iron_Deficiency',\n",
    "    'IP_SUS_RBC_HGB_Defect','IP_SUS_RBC_Fragments','IP_SUS_PLT_PLT_Clumps'\n",
    "]\n",
    "\n",
    "test_size      = 0.20\n",
    "random_seed    = 42\n",
    "top_k_features = 20\n",
    "TARGET_RECALL  = 0.975   # rerun with 0.975 for the 97.5% operating point\n",
    "\n",
    "# Tree complexity controls (tune as needed)\n",
    "criterion         = \"gini\"   # or \"entropy\" / \"log_loss\"\n",
    "max_depth         = 10\n",
    "min_samples_split = 20\n",
    "min_samples_leaf  = 10\n",
    "ccp_alpha         = 0.0\n",
    "\n",
    "# ========= 2) HELPERS =========\n",
    "def clean_colname(col: str) -> str:\n",
    "    col = (col\n",
    "           .replace(\" NRBC Present\", \"_NRBC_Present\")\n",
    "           .replace(\" IG Present\", \"_IG_Present\")\n",
    "           .replace(\" Dimorphic Population\", \"_Dimorphic_Population\")\n",
    "           .replace(\" Atypical Lympho\", \"_Atypical_Lympho\")\n",
    "           .replace(\" Turbidity_HGB Interf\", \"_Turbidity_HGB_Interf\"))\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    col = re.sub(r'__+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "def to_binary(series: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"1\":1,\"0\":0,\"yes\":1,\"no\":0,\"true\":1,\"false\":0,\"y\":1,\"n\":0,\n",
    "        \"present\":1,\"absent\":0,\"pos\":1,\"neg\":0,\"positive\":1,\"negative\":0,\n",
    "        \"abnormal\":1,\"normal\":0,\"clumps\":1,\"no_clumps\":0\n",
    "    }\n",
    "    s = series.astype(str).str.lower().str.strip().map(mapping)\n",
    "    if s.isna().any():\n",
    "        num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        s = s.where(~num.notna(), (num.fillna(0) != 0).astype(int))\n",
    "    return s.fillna(0).astype(int)\n",
    "\n",
    "def wilson_ci(k: int, n: int, alpha: float = 0.05):\n",
    "    \"\"\"95% Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (float(\"nan\"), float(\"nan\"))\n",
    "    z = 1.959963984540054\n",
    "    p = k / n\n",
    "    denom = 1 + (z**2)/n\n",
    "    center = (p + (z**2)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def metrics_with_cis(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    n_pos = tp + fn\n",
    "    n_neg = tn + fp\n",
    "\n",
    "    recall = tp / n_pos if n_pos else float(\"nan\")\n",
    "    spec   = tn / n_neg if n_neg else float(\"nan\")\n",
    "    ppv    = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv    = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"n_total\": int(len(y_true)), \"n_pos\": int(n_pos), \"n_neg\": int(n_neg),\n",
    "        \"recall\": recall, \"recall_ci\": wilson_ci(tp, n_pos),\n",
    "        \"specificity\": spec, \"specificity_ci\": wilson_ci(tn, n_neg),\n",
    "        \"ppv\": ppv, \"ppv_ci\": wilson_ci(tp, tp + fp) if (tp + fp) else (float(\"nan\"), float(\"nan\")),\n",
    "        \"npv\": npv, \"npv_ci\": wilson_ci(tn, tn + fn) if (tn + fn) else (float(\"nan\"), float(\"nan\")),\n",
    "    }\n",
    "\n",
    "def pct(x):\n",
    "    return 100.0 * x\n",
    "\n",
    "# ========= 3) LOAD & CLEAN COLUMN NAMES =========\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# ========= 4) VALIDATE REQUESTED COLUMNS =========\n",
    "want_cols = numeric_cols + binary_cols + [target_col]\n",
    "missing = [c for c in want_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Columns not found after cleaning. Adjust lists or cleaner:\")\n",
    "    for m in missing:\n",
    "        sug = get_close_matches(m, df.columns.tolist(), n=1, cutoff=0.7)\n",
    "        print(f\"  - {m}\" + (f\"  (closest: {sug[0]})\" if sug else \"\"))\n",
    "\n",
    "avail_numeric = [c for c in numeric_cols if c in df.columns]\n",
    "avail_binary  = [c for c in binary_cols  if c in df.columns]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# ========= 5) TYPE COERCION =========\n",
    "for c in avail_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in avail_binary:\n",
    "    df[c] = to_binary(df[c])\n",
    "\n",
    "df = df[~df[target_col].isna()].copy()\n",
    "\n",
    "y = df[target_col]\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = df[avail_numeric + avail_binary].fillna(0)\n",
    "\n",
    "const_cols = X.columns[X.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# ========= 6) SPLIT =========\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_seed, stratify=y\n",
    ")\n",
    "\n",
    "# ========= 7) DECISION TREE =========\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion=criterion,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=random_seed,\n",
    "    ccp_alpha=ccp_alpha\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# ========= 8) THRESHOLD TUNING (HIGHEST threshold meeting recall target) =========\n",
    "if len(np.unique(y_train)) != 2:\n",
    "    raise ValueError(\"This script expects a binary target for threshold tuning.\")\n",
    "\n",
    "y_proba = dt.predict_proba(X_test)[:, 1]\n",
    "thr_candidates = np.unique(np.r_[0.0, np.round(y_proba, 6), 1.0])\n",
    "\n",
    "rows = []\n",
    "for thr in thr_candidates:\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_hat, zero_division=0)\n",
    "    fn   = int(((y_test == 1) & (y_hat == 0)).sum())\n",
    "    fp   = int(((y_test == 0) & (y_hat == 1)).sum())\n",
    "    rows.append((thr, prec, rec, fn, fp))\n",
    "\n",
    "thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"FN\",\"FP\"])\n",
    "\n",
    "meets = thr_df[thr_df[\"recall\"] >= TARGET_RECALL]\n",
    "if len(meets):\n",
    "    best_row = meets.sort_values(by=[\"threshold\"], ascending=[False]).iloc[0]\n",
    "else:\n",
    "    best_row = thr_df.sort_values(by=[\"recall\",\"threshold\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "BEST_THR = float(best_row[\"threshold\"])\n",
    "print(f\"\\nChosen threshold = {BEST_THR:.6f} | recall={best_row['recall']:.4f} \"\n",
    "      f\"| precision={best_row['precision']:.4f} | FN={best_row['FN']} | FP={best_row['FP']}\")\n",
    "\n",
    "y_pred_thr = (y_proba >= BEST_THR).astype(int)\n",
    "\n",
    "print(\"\\n=== Report @ chosen threshold (recall-first, highest threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "print(\"Confusion matrix @ chosen threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_thr))\n",
    "\n",
    "# ========= 9) METRICS + 95% Wilson CIs =========\n",
    "m = metrics_with_cis(y_test, y_pred_thr)\n",
    "\n",
    "print(\"\\n=== Metrics with 95% Wilson CIs ===\")\n",
    "print(f\"Test set: N={m['n_total']} | positives={m['n_pos']} | negatives={m['n_neg']}\")\n",
    "print(f\"Recall/Sensitivity = {m['recall']:.4f} (95% CI {m['recall_ci'][0]:.4f}–{m['recall_ci'][1]:.4f})\")\n",
    "print(f\"Specificity         = {m['specificity']:.4f} (95% CI {m['specificity_ci'][0]:.4f}–{m['specificity_ci'][1]:.4f})\")\n",
    "print(f\"PPV                 = {m['ppv']:.4f} (95% CI {m['ppv_ci'][0]:.4f}–{m['ppv_ci'][1]:.4f})\")\n",
    "print(f\"NPV                 = {m['npv']:.4f} (95% CI {m['npv_ci'][0]:.4f}–{m['npv_ci'][1]:.4f})\")\n",
    "\n",
    "# ========= 10) ROC-AUC + PR-AUC =========\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    order = np.argsort(rec_curve)\n",
    "    pr_auc = np.trapz(prec_curve[order], rec_curve[order])\n",
    "    print(f\"\\nROC-AUC={roc:.4f} | PR-AUC≈{pr_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Could not compute ROC/PR AUC: {e}\")\n",
    "\n",
    "# ========= 11) TOP FEATURES =========\n",
    "importances = dt.feature_importances_\n",
    "imp = (pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "       .sort_values(\"Importance\", ascending=False)\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features:\")\n",
    "print(imp.head(top_k_features))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top = imp.head(top_k_features)[::-1]\n",
    "plt.barh(top[\"Feature\"], top[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_k_features} Feature Importances (Decision Tree)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========= 12) TREE SUMMARY (TOP LEVELS) =========\n",
    "print(\"\\n=== Tree (text summary, top levels) ===\")\n",
    "print(export_text(dt, feature_names=list(X.columns), max_depth=3))\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plot_tree(\n",
    "    dt,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"0\", \"1\"],\n",
    "    filled=True, rounded=True, max_depth=3, fontsize=8\n",
    ")\n",
    "plt.title(\"Decision Tree (top levels)\")\n",
    "plt.show()\n",
    "\n",
    "# ========= 13) DEPLOYMENT HINT =========\n",
    "# probs = dt.predict_proba(X_new)[:, 1]\n",
    "# preds = (probs >= BEST_THR).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e06bd2-4a58-4b23-b305-01077eb6ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== XGBOOST with Recall-First Threshold (choose HIGHEST threshold meeting target) ====\n",
    "# - Uses explicit numeric/binary columns\n",
    "# - Cleans column names to safe identifiers\n",
    "# - 80:20 split with stratify\n",
    "# - Handles imbalance via scale_pos_weight\n",
    "# - Picks the HIGHEST threshold with recall >= TARGET_RECALL (reduces FP flood)\n",
    "# - Prints metrics at chosen threshold + 95% Wilson CIs + PR-AUC/ROC-AUC\n",
    "# - Plots top features\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import get_close_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ========= 1) SETTINGS =========\n",
    "file_path  =  #### Your CSV Path #####\n",
    "target_col = \"anyflag\"\n",
    "\n",
    "numeric_cols = [\n",
    "    'age','Q_Flag_BlastsAbn_Lympho','Q_Flag_Blasts','Q_Flag_AbnLympho',\n",
    "    'Q_Flag_LeftShift','Q_Flag_Atypical_Lympho','Q_Flag_RBC_Agglutination',\n",
    "    'Q_Flag_TurbidityHGBInterf','Q_Flag_Iron_Deficiency','Q_FlagHGB_Defect',\n",
    "    'Q_Flag_Fragments','Q_Flag_PLT_Clumps','swbc','srbc','shgb','shct',\n",
    "    'smcv','smch','smchc','splt','srdw','srdw_1','spdw','smpv','slcr','spct',\n",
    "    'snrbc','snrbcpercent','sn','sl','smo','seo','sbaso','snper','slper',\n",
    "    'smoper','seoper','sbaper','sig','sigper','splti','MicroR','MacroR',\n",
    "    'tnc','ba_n','ba_n_per','wbc_D','tnc_D','NEUT_1','NEUTpercent',\n",
    "    'LYMP','LYMPper','HFLC','HFLCper','BA_D','BA_D_1','NE_SSC','NE_SFL',\n",
    "    'NE_FSC','LY_X','LY_Y','LY_Z','MO_X','MO_Y','MO_Z','NE_WX','NE_WY',\n",
    "    'NE_WZ','LY_WX','LY_WY','LY_WZ','MO_WX','MO_WY','MO_WZ'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'sex','WARD','WBC_Abnormal','WBC_Suspect','RBC_Abnormal','RBC_Suspect',\n",
    "    'PLT_Abnormal','PLT_Suspect','IP_ABN_WBC_Abn_Scattergram',\n",
    "    'IP_ABN_WBC_Neutropenia','IP_ABN_WBC_Neutrophilia',\n",
    "    'IP_ABN_WBC_Lymphopenia','IP_ABN_WBC_Lymphocytosis',\n",
    "    'IP_ABN_WBC_Monocytosis','IP_ABN_WBC_Eosinophilia','IP_ABN_WBC_Basophilia',\n",
    "    'IP_ABN_WBC_Leukocytopenia','IP_ABN_WBC_Leukocytosis',\n",
    "    'IP_ABN_WBC_NRBC_Present','IP_ABN_WBC_IG_Present',\n",
    "    'IP_ABN_RBC_RBC_Abn_Distribution','IP_ABN_RBC_Dimorphic_Population',\n",
    "    'IP_ABN_RBC_Anisocytosis','IP_ABN_RBC_Microcytosis','IP_ABN_RBC_Macrocytosis',\n",
    "    'IP_ABN_RBC_Hypochromia','IP_ABN_RBC_Anemia','IP_ABN_RBC_Erythrocytosis',\n",
    "    'IP_ABN_RBC_RET_Abn_Scattergram','IP_ABN_RBC_Reticulocytosis',\n",
    "    'IP_ABN_PLT_PLT_Abn_Distribution','IP_ABN_PLT_Thrombocytopenia',\n",
    "    'IP_ABN_PLT_Thrombocytosis','IP_ABN_PLT_PLT_Abn_Scattergram',\n",
    "    'IP_SUS_WBC_Blasts_Abn_Lympho','IP_SUS_WBC_Blasts',\n",
    "    'IP_SUS_WBC_Abn_Lympho','IP_SUS_WBC_Left_Shift',\n",
    "    'IP_SUS_WBC_Atypical_Lympho','IP_SUS_RBC_RBC_Agglutination',\n",
    "    'IP_SUS_RBC_Turbidity_HGB_Interf','IP_SUS_RBC_Iron_Deficiency',\n",
    "    'IP_SUS_RBC_HGB_Defect','IP_SUS_RBC_Fragments','IP_SUS_PLT_PLT_Clumps'\n",
    "]\n",
    "\n",
    "test_size      = 0.20\n",
    "random_seed    = 42\n",
    "top_k_features = 20\n",
    "\n",
    "# IMPORTANT: set TARGET_RECALL to 0.95 and rerun; then set to 0.975 and rerun\n",
    "TARGET_RECALL  = 0.95\n",
    "\n",
    "# ========= 2) HELPERS =========\n",
    "def clean_colname(col: str) -> str:\n",
    "    col = (col\n",
    "           .replace(\" NRBC Present\", \"_NRBC_Present\")\n",
    "           .replace(\" IG Present\", \"_IG_Present\")\n",
    "           .replace(\" Dimorphic Population\", \"_Dimorphic_Population\")\n",
    "           .replace(\" Atypical Lympho\", \"_Atypical_Lympho\")\n",
    "           .replace(\" Turbidity_HGB Interf\", \"_Turbidity_HGB_Interf\"))\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    col = re.sub(r'__+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "def to_binary(series: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"1\":1,\"0\":0,\"yes\":1,\"no\":0,\"true\":1,\"false\":0,\"y\":1,\"n\":0,\n",
    "        \"present\":1,\"absent\":0,\"pos\":1,\"neg\":0,\"positive\":1,\"negative\":0,\n",
    "        \"abnormal\":1,\"normal\":0,\"clumps\":1,\"no_clumps\":0\n",
    "    }\n",
    "    s = series.astype(str).str.lower().str.strip().map(mapping)\n",
    "    if s.isna().any():\n",
    "        num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        s = s.where(~num.notna(), (num.fillna(0) != 0).astype(int))\n",
    "    return s.fillna(0).astype(int)\n",
    "\n",
    "def wilson_ci(k: int, n: int, alpha: float = 0.05):\n",
    "    \"\"\"95% Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (float(\"nan\"), float(\"nan\"))\n",
    "    z = 1.959963984540054  # 95%\n",
    "    p = k / n\n",
    "    denom = 1 + (z**2)/n\n",
    "    center = (p + (z**2)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def approx_halfwidth(p: float, n: int):\n",
    "    \"\"\"Approx 95% CI half-width for planning.\"\"\"\n",
    "    if n <= 0:\n",
    "        return float(\"nan\")\n",
    "    z = 1.959963984540054\n",
    "    return z * math.sqrt(p*(1-p)/n)\n",
    "\n",
    "def metrics_with_cis(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    n_pos = tp + fn\n",
    "    n_neg = tn + fp\n",
    "\n",
    "    recall = tp / n_pos if n_pos else float(\"nan\")\n",
    "    spec   = tn / n_neg if n_neg else float(\"nan\")\n",
    "    ppv    = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv    = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"n_total\": int(len(y_true)), \"n_pos\": int(n_pos), \"n_neg\": int(n_neg),\n",
    "        \"recall\": recall, \"recall_ci\": wilson_ci(tp, n_pos),\n",
    "        \"specificity\": spec, \"specificity_ci\": wilson_ci(tn, n_neg),\n",
    "        \"ppv\": ppv, \"ppv_ci\": wilson_ci(tp, tp + fp) if (tp + fp) else (float(\"nan\"), float(\"nan\")),\n",
    "        \"npv\": npv, \"npv_ci\": wilson_ci(tn, tn + fn) if (tn + fn) else (float(\"nan\"), float(\"nan\")),\n",
    "    }\n",
    "\n",
    "# ========= 3) LOAD & CLEAN COLUMN NAMES =========\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# ========= 4) VALIDATE REQUESTED COLUMNS =========\n",
    "want_cols = numeric_cols + binary_cols + [target_col]\n",
    "missing = [c for c in want_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Columns not found after cleaning. Adjust lists or cleaner:\")\n",
    "    for m in missing:\n",
    "        sug = get_close_matches(m, df.columns.tolist(), n=1, cutoff=0.7)\n",
    "        print(f\"  - {m}\" + (f\"  (closest: {sug[0]})\" if sug else \"\"))\n",
    "\n",
    "avail_numeric = [c for c in numeric_cols if c in df.columns]\n",
    "avail_binary  = [c for c in binary_cols  if c in df.columns]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# ========= 5) TYPE COERCION =========\n",
    "for c in avail_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in avail_binary:\n",
    "    df[c] = to_binary(df[c])\n",
    "\n",
    "df = df[~df[target_col].isna()].copy()\n",
    "\n",
    "y = df[target_col]\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = df[avail_numeric + avail_binary].fillna(0)\n",
    "\n",
    "# Drop constant columns\n",
    "const_cols = X.columns[X.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# ========= 6) SPLIT =========\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_seed, stratify=y\n",
    ")\n",
    "\n",
    "# ========= 7) XGB MODEL =========\n",
    "n_classes = int(len(np.unique(y_train)))\n",
    "if n_classes != 2:\n",
    "    raise ValueError(f\"Expected binary target, but got {n_classes} classes.\")\n",
    "\n",
    "pos = int((y_train == 1).sum())\n",
    "neg = int((y_train == 0).sum())\n",
    "spw = float(neg) / max(1.0, float(pos))\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    max_delta_step=1,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=random_seed,\n",
    "    scale_pos_weight=spw\n",
    ")\n",
    "\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ========= 8) THRESHOLD TUNING (Highest threshold with recall >= target) =========\n",
    "y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thr_candidates = np.unique(np.r_[0.0, np.round(y_proba, 6), 1.0])\n",
    "\n",
    "rows = []\n",
    "for thr in thr_candidates:\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_hat, zero_division=0)\n",
    "    fn   = int(((y_test == 1) & (y_hat == 0)).sum())\n",
    "    fp   = int(((y_test == 0) & (y_hat == 1)).sum())\n",
    "    rows.append((thr, prec, rec, fn, fp))\n",
    "\n",
    "thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"FN\",\"FP\"])\n",
    "\n",
    "meets = thr_df[thr_df[\"recall\"] >= TARGET_RECALL]\n",
    "if len(meets):\n",
    "    # Choose the HIGHEST threshold that still meets recall (reduces FP flood)\n",
    "    best_row = meets.sort_values(by=[\"threshold\"], ascending=[False]).iloc[0]\n",
    "else:\n",
    "    # If target recall not achievable: maximize recall, then maximize threshold\n",
    "    best_row = thr_df.sort_values(by=[\"recall\",\"threshold\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "BEST_THR = float(best_row[\"threshold\"])\n",
    "print(f\"\\nChosen threshold = {BEST_THR:.6f} | recall={best_row['recall']:.4f} \"\n",
    "      f\"| precision={best_row['precision']:.4f} | FN={best_row['FN']} | FP={best_row['FP']}\")\n",
    "\n",
    "y_pred_thr = (y_proba >= BEST_THR).astype(int)\n",
    "\n",
    "print(\"\\n=== Report @ chosen threshold (recall-first, highest threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "print(\"Confusion matrix @ chosen threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_thr))\n",
    "\n",
    "# ========= 9) METRICS + 95% Wilson CIs =========\n",
    "m = metrics_with_cis(y_test, y_pred_thr)\n",
    "\n",
    "print(\"\\n=== Metrics with 95% Wilson CIs ===\")\n",
    "print(f\"Test set: N={m['n_total']} | positives={m['n_pos']} | negatives={m['n_neg']}\")\n",
    "print(f\"Recall/Sensitivity = {m['recall']:.4f} (95% CI {m['recall_ci'][0]:.4f}–{m['recall_ci'][1]:.4f})\")\n",
    "print(f\"Specificity         = {m['specificity']:.4f} (95% CI {m['specificity_ci'][0]:.4f}–{m['specificity_ci'][1]:.4f})\")\n",
    "print(f\"PPV                 = {m['ppv']:.4f} (95% CI {m['ppv_ci'][0]:.4f}–{m['ppv_ci'][1]:.4f})\")\n",
    "print(f\"NPV                 = {m['npv']:.4f} (95% CI {m['npv_ci'][0]:.4f}–{m['npv_ci'][1]:.4f})\")\n",
    "\n",
    "# Adequacy / precision of recall estimate depends on number of positives\n",
    "hw_if_95  = approx_halfwidth(0.95,  m[\"n_pos\"])\n",
    "hw_if_975 = approx_halfwidth(0.975, m[\"n_pos\"])\n",
    "print(\"\\n=== Recall precision (approx; depends on #positives in test set) ===\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.95  : ±{hw_if_95:.4f}\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.975 : ±{hw_if_975:.4f}\")\n",
    "\n",
    "# ========= 10) ROC-AUC + PR-AUC (robust integration) =========\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    order = np.argsort(rec_curve)\n",
    "    pr_auc = np.trapz(prec_curve[order], rec_curve[order])\n",
    "    print(f\"\\nROC-AUC={roc:.4f} | PR-AUC≈{pr_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Could not compute ROC/PR AUC: {e}\")\n",
    "\n",
    "# ========= 11) FEATURE IMPORTANCE PLOT =========\n",
    "importances = xgb.feature_importances_\n",
    "imp = (pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "       .sort_values(\"Importance\", ascending=False)\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features:\")\n",
    "print(imp.head(top_k_features))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top = imp.head(top_k_features)[::-1]\n",
    "plt.barh(top[\"Feature\"], top[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_k_features} Feature Importances (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========= 12) DEPLOYMENT HINT =========\n",
    "# probs = xgb.predict_proba(X_new)[:, 1]\n",
    "# preds = (probs >= BEST_THR).astype(int)   # use BEST_THR chosen above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745419e-4889-48cc-821e-2476a196d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== XGBOOST with Recall-First Threshold (choose HIGHEST threshold meeting target) ====\n",
    "# - Uses explicit numeric/binary columns\n",
    "# - Cleans column names to safe identifiers\n",
    "# - 80:20 split with stratify\n",
    "# - Handles imbalance via scale_pos_weight\n",
    "# - Picks the HIGHEST threshold with recall >= TARGET_RECALL (reduces FP flood)\n",
    "# - Prints metrics at chosen threshold + 95% Wilson CIs + PR-AUC/ROC-AUC\n",
    "# - Plots top features\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from difflib import get_close_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ========= 1) SETTINGS =========\n",
    "file_path  =  #### Your CSV Path #####\n",
    "target_col = \"anyflag\"\n",
    "\n",
    "numeric_cols = [\n",
    "    'age','Q_Flag_BlastsAbn_Lympho','Q_Flag_Blasts','Q_Flag_AbnLympho',\n",
    "    'Q_Flag_LeftShift','Q_Flag_Atypical_Lympho','Q_Flag_RBC_Agglutination',\n",
    "    'Q_Flag_TurbidityHGBInterf','Q_Flag_Iron_Deficiency','Q_FlagHGB_Defect',\n",
    "    'Q_Flag_Fragments','Q_Flag_PLT_Clumps','swbc','srbc','shgb','shct',\n",
    "    'smcv','smch','smchc','splt','srdw','srdw_1','spdw','smpv','slcr','spct',\n",
    "    'snrbc','snrbcpercent','sn','sl','smo','seo','sbaso','snper','slper',\n",
    "    'smoper','seoper','sbaper','sig','sigper','splti','MicroR','MacroR',\n",
    "    'tnc','ba_n','ba_n_per','wbc_D','tnc_D','NEUT_1','NEUTpercent',\n",
    "    'LYMP','LYMPper','HFLC','HFLCper','BA_D','BA_D_1','NE_SSC','NE_SFL',\n",
    "    'NE_FSC','LY_X','LY_Y','LY_Z','MO_X','MO_Y','MO_Z','NE_WX','NE_WY',\n",
    "    'NE_WZ','LY_WX','LY_WY','LY_WZ','MO_WX','MO_WY','MO_WZ'\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    'sex','WARD','WBC_Abnormal','WBC_Suspect','RBC_Abnormal','RBC_Suspect',\n",
    "    'PLT_Abnormal','PLT_Suspect','IP_ABN_WBC_Abn_Scattergram',\n",
    "    'IP_ABN_WBC_Neutropenia','IP_ABN_WBC_Neutrophilia',\n",
    "    'IP_ABN_WBC_Lymphopenia','IP_ABN_WBC_Lymphocytosis',\n",
    "    'IP_ABN_WBC_Monocytosis','IP_ABN_WBC_Eosinophilia','IP_ABN_WBC_Basophilia',\n",
    "    'IP_ABN_WBC_Leukocytopenia','IP_ABN_WBC_Leukocytosis',\n",
    "    'IP_ABN_WBC_NRBC_Present','IP_ABN_WBC_IG_Present',\n",
    "    'IP_ABN_RBC_RBC_Abn_Distribution','IP_ABN_RBC_Dimorphic_Population',\n",
    "    'IP_ABN_RBC_Anisocytosis','IP_ABN_RBC_Microcytosis','IP_ABN_RBC_Macrocytosis',\n",
    "    'IP_ABN_RBC_Hypochromia','IP_ABN_RBC_Anemia','IP_ABN_RBC_Erythrocytosis',\n",
    "    'IP_ABN_RBC_RET_Abn_Scattergram','IP_ABN_RBC_Reticulocytosis',\n",
    "    'IP_ABN_PLT_PLT_Abn_Distribution','IP_ABN_PLT_Thrombocytopenia',\n",
    "    'IP_ABN_PLT_Thrombocytosis','IP_ABN_PLT_PLT_Abn_Scattergram',\n",
    "    'IP_SUS_WBC_Blasts_Abn_Lympho','IP_SUS_WBC_Blasts',\n",
    "    'IP_SUS_WBC_Abn_Lympho','IP_SUS_WBC_Left_Shift',\n",
    "    'IP_SUS_WBC_Atypical_Lympho','IP_SUS_RBC_RBC_Agglutination',\n",
    "    'IP_SUS_RBC_Turbidity_HGB_Interf','IP_SUS_RBC_Iron_Deficiency',\n",
    "    'IP_SUS_RBC_HGB_Defect','IP_SUS_RBC_Fragments','IP_SUS_PLT_PLT_Clumps'\n",
    "]\n",
    "\n",
    "test_size      = 0.20\n",
    "random_seed    = 42\n",
    "top_k_features = 20\n",
    "\n",
    "# IMPORTANT: set TARGET_RECALL to 0.95 and rerun; then set to 0.975 and rerun\n",
    "TARGET_RECALL  = 0.975\n",
    "\n",
    "# ========= 2) HELPERS =========\n",
    "def clean_colname(col: str) -> str:\n",
    "    col = (col\n",
    "           .replace(\" NRBC Present\", \"_NRBC_Present\")\n",
    "           .replace(\" IG Present\", \"_IG_Present\")\n",
    "           .replace(\" Dimorphic Population\", \"_Dimorphic_Population\")\n",
    "           .replace(\" Atypical Lympho\", \"_Atypical_Lympho\")\n",
    "           .replace(\" Turbidity_HGB Interf\", \"_Turbidity_HGB_Interf\"))\n",
    "    col = re.sub(r'[^0-9a-zA-Z_]', '_', col)\n",
    "    col = re.sub(r'__+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "def to_binary(series: pd.Series) -> pd.Series:\n",
    "    mapping = {\n",
    "        \"1\":1,\"0\":0,\"yes\":1,\"no\":0,\"true\":1,\"false\":0,\"y\":1,\"n\":0,\n",
    "        \"present\":1,\"absent\":0,\"pos\":1,\"neg\":0,\"positive\":1,\"negative\":0,\n",
    "        \"abnormal\":1,\"normal\":0,\"clumps\":1,\"no_clumps\":0\n",
    "    }\n",
    "    s = series.astype(str).str.lower().str.strip().map(mapping)\n",
    "    if s.isna().any():\n",
    "        num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        s = s.where(~num.notna(), (num.fillna(0) != 0).astype(int))\n",
    "    return s.fillna(0).astype(int)\n",
    "\n",
    "def wilson_ci(k: int, n: int, alpha: float = 0.05):\n",
    "    \"\"\"95% Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n <= 0:\n",
    "        return (float(\"nan\"), float(\"nan\"))\n",
    "    z = 1.959963984540054  # 95%\n",
    "    p = k / n\n",
    "    denom = 1 + (z**2)/n\n",
    "    center = (p + (z**2)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p) + (z**2)/(4*n)) / n)) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def approx_halfwidth(p: float, n: int):\n",
    "    \"\"\"Approx 95% CI half-width for planning.\"\"\"\n",
    "    if n <= 0:\n",
    "        return float(\"nan\")\n",
    "    z = 1.959963984540054\n",
    "    return z * math.sqrt(p*(1-p)/n)\n",
    "\n",
    "def metrics_with_cis(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    n_pos = tp + fn\n",
    "    n_neg = tn + fp\n",
    "\n",
    "    recall = tp / n_pos if n_pos else float(\"nan\")\n",
    "    spec   = tn / n_neg if n_neg else float(\"nan\")\n",
    "    ppv    = tp / (tp + fp) if (tp + fp) else float(\"nan\")\n",
    "    npv    = tn / (tn + fn) if (tn + fn) else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"n_total\": int(len(y_true)), \"n_pos\": int(n_pos), \"n_neg\": int(n_neg),\n",
    "        \"recall\": recall, \"recall_ci\": wilson_ci(tp, n_pos),\n",
    "        \"specificity\": spec, \"specificity_ci\": wilson_ci(tn, n_neg),\n",
    "        \"ppv\": ppv, \"ppv_ci\": wilson_ci(tp, tp + fp) if (tp + fp) else (float(\"nan\"), float(\"nan\")),\n",
    "        \"npv\": npv, \"npv_ci\": wilson_ci(tn, tn + fn) if (tn + fn) else (float(\"nan\"), float(\"nan\")),\n",
    "    }\n",
    "\n",
    "# ========= 3) LOAD & CLEAN COLUMN NAMES =========\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "df.columns = [clean_colname(c) for c in df.columns]\n",
    "\n",
    "# ========= 4) VALIDATE REQUESTED COLUMNS =========\n",
    "want_cols = numeric_cols + binary_cols + [target_col]\n",
    "missing = [c for c in want_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Columns not found after cleaning. Adjust lists or cleaner:\")\n",
    "    for m in missing:\n",
    "        sug = get_close_matches(m, df.columns.tolist(), n=1, cutoff=0.7)\n",
    "        print(f\"  - {m}\" + (f\"  (closest: {sug[0]})\" if sug else \"\"))\n",
    "\n",
    "avail_numeric = [c for c in numeric_cols if c in df.columns]\n",
    "avail_binary  = [c for c in binary_cols  if c in df.columns]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise KeyError(f\"Target column '{target_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# ========= 5) TYPE COERCION =========\n",
    "for c in avail_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in avail_binary:\n",
    "    df[c] = to_binary(df[c])\n",
    "\n",
    "df = df[~df[target_col].isna()].copy()\n",
    "\n",
    "y = df[target_col]\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(\"category\").cat.codes\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = df[avail_numeric + avail_binary].fillna(0)\n",
    "\n",
    "# Drop constant columns\n",
    "const_cols = X.columns[X.nunique() <= 1].tolist()\n",
    "if const_cols:\n",
    "    X = X.drop(columns=const_cols)\n",
    "\n",
    "# ========= 6) SPLIT =========\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_seed, stratify=y\n",
    ")\n",
    "\n",
    "# ========= 7) XGB MODEL =========\n",
    "n_classes = int(len(np.unique(y_train)))\n",
    "if n_classes != 2:\n",
    "    raise ValueError(f\"Expected binary target, but got {n_classes} classes.\")\n",
    "\n",
    "pos = int((y_train == 1).sum())\n",
    "neg = int((y_train == 0).sum())\n",
    "spw = float(neg) / max(1.0, float(pos))\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    max_delta_step=1,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=random_seed,\n",
    "    scale_pos_weight=spw\n",
    ")\n",
    "\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ========= 8) THRESHOLD TUNING (Highest threshold with recall >= target) =========\n",
    "y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thr_candidates = np.unique(np.r_[0.0, np.round(y_proba, 6), 1.0])\n",
    "\n",
    "rows = []\n",
    "for thr in thr_candidates:\n",
    "    y_hat = (y_proba >= thr).astype(int)\n",
    "    prec = precision_score(y_test, y_hat, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_hat, zero_division=0)\n",
    "    fn   = int(((y_test == 1) & (y_hat == 0)).sum())\n",
    "    fp   = int(((y_test == 0) & (y_hat == 1)).sum())\n",
    "    rows.append((thr, prec, rec, fn, fp))\n",
    "\n",
    "thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"FN\",\"FP\"])\n",
    "\n",
    "meets = thr_df[thr_df[\"recall\"] >= TARGET_RECALL]\n",
    "if len(meets):\n",
    "    # Choose the HIGHEST threshold that still meets recall (reduces FP flood)\n",
    "    best_row = meets.sort_values(by=[\"threshold\"], ascending=[False]).iloc[0]\n",
    "else:\n",
    "    # If target recall not achievable: maximize recall, then maximize threshold\n",
    "    best_row = thr_df.sort_values(by=[\"recall\",\"threshold\"], ascending=[False, False]).iloc[0]\n",
    "\n",
    "BEST_THR = float(best_row[\"threshold\"])\n",
    "print(f\"\\nChosen threshold = {BEST_THR:.6f} | recall={best_row['recall']:.4f} \"\n",
    "      f\"| precision={best_row['precision']:.4f} | FN={best_row['FN']} | FP={best_row['FP']}\")\n",
    "\n",
    "y_pred_thr = (y_proba >= BEST_THR).astype(int)\n",
    "\n",
    "print(\"\\n=== Report @ chosen threshold (recall-first, highest threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "print(\"Confusion matrix @ chosen threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_thr))\n",
    "\n",
    "# ========= 9) METRICS + 95% Wilson CIs =========\n",
    "m = metrics_with_cis(y_test, y_pred_thr)\n",
    "\n",
    "print(\"\\n=== Metrics with 95% Wilson CIs ===\")\n",
    "print(f\"Test set: N={m['n_total']} | positives={m['n_pos']} | negatives={m['n_neg']}\")\n",
    "print(f\"Recall/Sensitivity = {m['recall']:.4f} (95% CI {m['recall_ci'][0]:.4f}–{m['recall_ci'][1]:.4f})\")\n",
    "print(f\"Specificity         = {m['specificity']:.4f} (95% CI {m['specificity_ci'][0]:.4f}–{m['specificity_ci'][1]:.4f})\")\n",
    "print(f\"PPV                 = {m['ppv']:.4f} (95% CI {m['ppv_ci'][0]:.4f}–{m['ppv_ci'][1]:.4f})\")\n",
    "print(f\"NPV                 = {m['npv']:.4f} (95% CI {m['npv_ci'][0]:.4f}–{m['npv_ci'][1]:.4f})\")\n",
    "\n",
    "# Adequacy / precision of recall estimate depends on number of positives\n",
    "hw_if_95  = approx_halfwidth(0.95,  m[\"n_pos\"])\n",
    "hw_if_975 = approx_halfwidth(0.975, m[\"n_pos\"])\n",
    "print(\"\\n=== Recall precision (approx; depends on #positives in test set) ===\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.95  : ±{hw_if_95:.4f}\")\n",
    "print(f\"Approx 95% CI half-width if true recall=0.975 : ±{hw_if_975:.4f}\")\n",
    "\n",
    "# ========= 10) ROC-AUC + PR-AUC (robust integration) =========\n",
    "try:\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    order = np.argsort(rec_curve)\n",
    "    pr_auc = np.trapz(prec_curve[order], rec_curve[order])\n",
    "    print(f\"\\nROC-AUC={roc:.4f} | PR-AUC≈{pr_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[WARN] Could not compute ROC/PR AUC: {e}\")\n",
    "\n",
    "# ========= 11) FEATURE IMPORTANCE PLOT =========\n",
    "importances = xgb.feature_importances_\n",
    "imp = (pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "       .sort_values(\"Importance\", ascending=False)\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features:\")\n",
    "print(imp.head(top_k_features))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top = imp.head(top_k_features)[::-1]\n",
    "plt.barh(top[\"Feature\"], top[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_k_features} Feature Importances (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========= 12) DEPLOYMENT HINT =========\n",
    "# probs = xgb.predict_proba(X_new)[:, 1]\n",
    "# preds = (probs >= BEST_THR).astype(int)   # use BEST_THR chosen above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155f333-9588-45a1-83bf-d6b8e9a40d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
